{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95527838-4ecc-4615-a34d-ed3970ae3ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# stats import\n",
    "n_permutation = 10000\n",
    "from scipy.stats import permutation_test\n",
    "def statistic(condA, condB, axis):\n",
    "    return np.nanmean(condA, axis=axis) - np.nanmean(condB, axis=axis)\n",
    "\n",
    "# Define parameters\n",
    "subjects = ['sub-001', 'sub-002', 'sub-003', 'sub-004',\n",
    "            'sub-005', 'sub-006', 'sub-007', 'sub-008']\n",
    "subjects_plot = ['sub-001', 'sub-002', 'sub-003', 'sub-004',\n",
    "                 'sub-005', 'sub-006', 'sub-007', 'sub-008', 'group']\n",
    "tasks = ['FullScreen', 'FullScreenAttendFix', 'FullScreenAttendBar']\n",
    "rois = ['V1', 'V2', 'V3', 'V3AB', 'hMT+', 'LO',\n",
    "        'VO', 'iIPS', 'sIPS', 'iPCS', 'sPCS', 'mPCS']\n",
    "\n",
    "# Define folders\n",
    "base_dir = '/home/mszinte/disks/meso_S/data/gaze_prf'\n",
    "bids_dir = \"{}\".format(base_dir)\n",
    "pp_dir = \"{}/derivatives/pp_data\".format(base_dir)\n",
    "\n",
    "# analysis settings\n",
    "best_voxels_num = 250\n",
    "type_analyses = ['','_best{}'.format(best_voxels_num)]\n",
    "\n",
    "cortical_mask = 'cortical'\n",
    "n_ecc_bins=10\n",
    "verbose = False\n",
    "TR = 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781fbae-58f3-4a6d-abe1-78c3837f2d45",
   "metadata": {},
   "source": [
    "### Compute TSV files for fullscreen atention R2 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb4c46-0199-42cb-9b4d-69f2aae725a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create TSV files\n",
    "group_tsv_dir = '{}/{}/prf/tsv'.format(pp_dir, 'group')\n",
    "try: os.makedirs(group_tsv_dir)\n",
    "except: pass\n",
    "\n",
    "for task in tasks:\n",
    "    for subject_num, subject in enumerate(subjects):\n",
    "        # define folders\n",
    "        fit_dir = '{}/{}/prf/fit'.format(pp_dir, subject)\n",
    "        mask_dir = '{}/{}/masks'.format(pp_dir, subject)\n",
    "        tsv_dir = '{}/{}/prf/tsv'.format(pp_dir, subject)\n",
    "        try: os.makedirs(tsv_dir)\n",
    "        except: pass\n",
    "\n",
    "        # load pRF threshold masks\n",
    "        th_mat = nb.load('{}/{}_task-{}_prf_threshold.nii.gz'.format(mask_dir,subject,task)).get_fdata()\n",
    "\n",
    "        # load fit parameters x by threshold\n",
    "        r2_th_mat = nb.load('{}/{}_task-{}_par-r2.nii.gz'.format(fit_dir,subject,task)).get_fdata()*th_mat\n",
    "        ecc_th_mat = nb.load('{}/{}_task-{}_par-ecc.nii.gz'.format(fit_dir,subject,task)).get_fdata()*th_mat\n",
    "        sd_th_mat = nb.load('{}/{}_task-{}_par-sd.nii.gz'.format(fit_dir,subject,task)).get_fdata()*th_mat\n",
    "        x_th_mat = nb.load('{}/{}_task-{}_par-x.nii.gz'.format(fit_dir,subject,task)).get_fdata()*th_mat\n",
    "        y_th_mat = nb.load('{}/{}_task-{}_par-y.nii.gz'.format(fit_dir,subject,task)).get_fdata()*th_mat\n",
    "        amp_th_mat = nb.load('{}/{}_task-{}_par-amplitude.nii.gz'.format(fit_dir,subject,task)).get_fdata()*th_mat\n",
    "        bsl_th_mat = nb.load('{}/{}_task-{}_par-baseline.nii.gz'.format(fit_dir,subject,task)).get_fdata()*th_mat\n",
    "        \n",
    "        # creat tsv\n",
    "        for roi_num, roi in enumerate(rois):\n",
    "            # load roi\n",
    "            lh_mat = nb.load(\"{}/{}_{}_L.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            rh_mat = nb.load(\"{}/{}_{}_R.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            roi_mat = lh_mat + rh_mat\n",
    "            roi_mat[roi_mat==0] = np.nan\n",
    "\n",
    "            # select data by roi mask\n",
    "            r2_roi_th_mat = r2_th_mat[roi_mat==True]\n",
    "            ecc_roi_th_mat = ecc_th_mat[roi_mat==True]\n",
    "            sd_roi_th_mat = sd_th_mat[roi_mat==True]\n",
    "            x_roi_th_mat = x_th_mat[roi_mat==True]\n",
    "            y_roi_th_mat = y_th_mat[roi_mat==True]\n",
    "            amp_roi_th_mat = amp_th_mat[roi_mat==True]\n",
    "            bsl_roi_th_mat = bsl_th_mat[roi_mat==True]\n",
    "            \n",
    "            # create dataframe\n",
    "            df_roi = pd.DataFrame({'subject': [subject] * r2_roi_th_mat.shape[0],\n",
    "                                   'roi': [roi] * r2_roi_th_mat.shape[0],\n",
    "                                   'r2': r2_roi_th_mat,\n",
    "                                   'ecc': ecc_roi_th_mat,\n",
    "                                   'sd': sd_roi_th_mat,\n",
    "                                   'x': x_roi_th_mat,\n",
    "                                   'y': y_roi_th_mat,\n",
    "                                   'amplitude': amp_roi_th_mat,\n",
    "                                   'baseline': bsl_roi_th_mat})\n",
    "\n",
    "            # rank based on r2\n",
    "            if task == 'FullScreen': \n",
    "                df_roi['rank_fs_r2']=df_roi.groupby('roi')['r2'].rank(method='max',ascending=False)\n",
    "            else:\n",
    "                df_fs = pd.read_csv(\"{}/{}_task-FullScreen_prf_threshold_par.tsv\".format(tsv_dir,subject,task),sep=\"\\t\")\n",
    "                df_roi['rank_fs_r2'] = np.array(df_fs.loc[(df_fs.roi == roi)]['rank_fs_r2'])\n",
    "                \n",
    "            # get best voxels\n",
    "            df_best_roi = df_roi[(df_roi.rank_fs_r2<=best_voxels_num)]\n",
    "            \n",
    "            # across roi\n",
    "            if roi_num > 0: \n",
    "                df = pd.concat([df,df_roi], ignore_index=True)\n",
    "                df_best = pd.concat([df_best,df_best_roi], ignore_index=True)                \n",
    "            else:\n",
    "                df = df_roi\n",
    "                df_best = df_best_roi\n",
    "        \n",
    "        # save dataframe\n",
    "        df_fn = \"{}/{}_task-{}_prf_threshold_par.tsv\".format(tsv_dir,subject,task)\n",
    "        print('saving {}'.format(df_fn))\n",
    "        df.to_csv(df_fn, sep=\"\\t\", na_rep='NaN',index=False)\n",
    "        \n",
    "        df_best_fn = \"{}/{}_task-{}_prf_threshold_par_best{}.tsv\".format(tsv_dir,subject,task,int(best_voxels_num))\n",
    "        print('saving {}'.format(df_best_fn))\n",
    "        df_best.to_csv(df_best_fn, sep=\"\\t\", na_rep='NaN',index=False)\n",
    "        \n",
    "        # across subject\n",
    "        if subject_num == 0: df_group = df\n",
    "        else: df_group = pd.concat([df_group, df])\n",
    "        \n",
    "        if subject_num == 0: df_best_group = df_best\n",
    "        else: df_best_group = pd.concat([df_best_group, df_best])\n",
    "        \n",
    "    # save group data\n",
    "    df_group_fn = \"{}/group_task-{}_prf_threshold_par.tsv\".format(group_tsv_dir,task)\n",
    "    print('saving {}'.format(df_group_fn))\n",
    "    df_group.to_csv(df_group_fn, sep=\"\\t\", na_rep='NaN')\n",
    "    \n",
    "    df_best_group_fn = \"{}/group_task-{}_prf_threshold_par_best{}.tsv\".format(group_tsv_dir,task,int(best_voxels_num))\n",
    "    print('saving {}'.format(df_best_group_fn))\n",
    "    df_best_group.to_csv(df_best_group_fn, sep=\"\\t\", na_rep='NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a6aba-e67d-489a-a827-1212a89c5fc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compute time series / parameters / predictions TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fd771-c999-45d7-a7ef-f002b8470de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for type_analysis in type_analyses:\n",
    "    for subject in subjects:\n",
    "\n",
    "        print('\\n{}...'.format(subject))\n",
    "        # define folders\n",
    "        fit_dir = '{}/{}/prf/fit'.format(pp_dir, subject)\n",
    "        func_avg_dir = '{}/{}/func_avg'.format(pp_dir, subject)\n",
    "        pred_dir = '{}/{}/prf/predictions'.format(pp_dir, subject)\n",
    "        mask_dir = '{}/{}/masks'.format(pp_dir, subject)\n",
    "        tsv_dir = '{}/{}/prf/tsv'.format(pp_dir, subject)\n",
    "        try: os.makedirs(tsv_dir)\n",
    "        except: pass\n",
    "\n",
    "        # load pRF threshold masks\n",
    "        th_mat = nb.load('{}/{}_task-FullScreen_prf_threshold.nii.gz'.format(mask_dir,subject)).get_fdata()\n",
    "\n",
    "        # define empty coordinates index\n",
    "        x_idx, y_idx, z_idx = np.zeros_like(th_mat), np.zeros_like(th_mat), np.zeros_like(th_mat)\n",
    "        for x in np.arange(th_mat.shape[0]):\n",
    "            for y in np.arange(th_mat.shape[1]):\n",
    "                for z in np.arange(th_mat.shape[2]):\n",
    "                    x_idx[x,y,z], y_idx[x,y,z], z_idx[x,y,z] = x, y, z\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Load fit parameters\n",
    "        print('\\nLoad fit parameters...')\n",
    "        for attend_task, attend_task_short in zip(['','AttendFix','AttendBar'], ['', '_af', '_ab']):\n",
    "            for fit_param in ['amplitude','baseline','ecc','r2','sd','x','y','theta']:\n",
    "                exec(\"fs{}_{} = nb.load('{}/{}_task-FullScreen{}_par-{}.nii.gz').get_fdata()*th_mat\".format(\n",
    "                    attend_task_short,fit_param,fit_dir,subject,attend_task,fit_param))\n",
    "                if verbose: print(\"load fs{}_{}\".format(attend_task_short,fit_param))\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Create dataframe with fit parameters\n",
    "        print('\\nCreate dataframe with fit parameters...')\n",
    "        for roi_num, roi in enumerate(rois):\n",
    "            # load roi\n",
    "            lh_mat = nb.load(\"{}/{}_{}_L.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            rh_mat = nb.load(\"{}/{}_{}_R.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            roi_mat = lh_mat + rh_mat\n",
    "            roi_mat[roi_mat==0] = np.nan\n",
    "\n",
    "            # create dataframe\n",
    "            df_roi = pd.DataFrame({'subject': [subject] * fs_r2[roi_mat==True].shape[0]})\n",
    "            df_roi['roi'] = [roi] * fs_r2[roi_mat==True].shape[0]\n",
    "            df_roi['vox_coord'] = np.array([x_idx[roi_mat==True],y_idx[roi_mat==True],z_idx[roi_mat==True]]).T.tolist()        \n",
    "\n",
    "            # fullscreen parameters\n",
    "            for attend_task in ['', '_ab', '_af']:\n",
    "                for fit_param in ['amplitude','baseline','ecc','r2','sd','x','y','theta']:\n",
    "                    exec(\"df_roi['{}_fs{}'] = fs{}_{}[roi_mat==True]\".format(fit_param, attend_task, attend_task, fit_param))\n",
    "                    if roi_num == 11:\n",
    "                        if verbose: print(\"create df['{}_fs{}']\".format(fit_param, attend_task))\n",
    "                        exec(\"del fs{}_{}\".format(attend_task, fit_param))\n",
    "                        if verbose: print(\"delete fs{}_{} from working memory\".format(attend_task, fit_param))\n",
    "\n",
    "\n",
    "            # get rank with fs\n",
    "            df_roi['rank_r2_fs'] = df_roi.groupby('roi')['r2_fs'].rank(method='max', ascending=False)\n",
    "\n",
    "            # keep best 250\n",
    "            if type_analysis == '_best{}'.format(best_voxels_num):\n",
    "                df_roi = df_roi[(df_roi.rank_r2_fs<=best_voxels_num)]\n",
    "\n",
    "            # across roi\n",
    "            if roi_num > 0: df = pd.concat([df,df_roi], ignore_index=True)\n",
    "            else: df = df_roi\n",
    "\n",
    "        \n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Load time series (only for best 250 voxels)\n",
    "        if type_analysis == '_best{}'.format(best_voxels_num):\n",
    "            \n",
    "            print('\\nLoad time series...')\n",
    "            for main_task, main_task_short in zip(['FullScreen', 'GazeCenter', 'GazeLeft', 'GazeRight'], ['fs', 'gc', 'gl', 'gr']):\n",
    "                if main_task == 'FullScreen':\n",
    "                    attend_tasks = ['','AttendFix','AttendBar']\n",
    "                    attend_tasks_short = ['','_af','_ab']\n",
    "                else:\n",
    "                    attend_tasks = ['AttendFix','AttendBar']\n",
    "                    attend_tasks_short = ['_af','_ab']\n",
    "\n",
    "                for attend_task, attend_task_short in zip(attend_tasks, attend_tasks_short):\n",
    "                    exec(\"{}{}_ts = nb.load('{}/{}_task-{}{}_fmriprep_dct_avg.nii.gz').get_fdata()\".format(\n",
    "                        main_task_short, attend_task_short, func_avg_dir, subject, main_task, attend_task))\n",
    "                    if verbose: print(\"load {}{}_ts\".format(main_task_short, attend_task_short))\n",
    "\n",
    "            # -------------------------------------------------------------------------------------------------------\n",
    "            # Add timeseries to the dataframe\n",
    "            print('\\nAdd timeseries to the dataframe...')\n",
    "            fs_r2 = nb.load('{}/{}_task-FullScreen_par-r2.nii.gz'.format(fit_dir,subject)).get_fdata()*th_mat\n",
    "            for roi_num, roi in enumerate(rois):\n",
    "                # load roi\n",
    "                lh_mat = nb.load(\"{}/{}_{}_L.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "                rh_mat = nb.load(\"{}/{}_{}_R.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "                roi_mat = lh_mat + rh_mat\n",
    "                roi_mat[roi_mat==0] = np.nan\n",
    "\n",
    "                # create dataframe\n",
    "                df_roi = pd.DataFrame({'subject': [subject] * fs_r2[roi_mat==True].shape[0]})\n",
    "                df_roi['roi'] = [roi] * fs_r2[roi_mat==True].shape[0]\n",
    "\n",
    "                # fullscreen r2 parameter\n",
    "                df_roi['r2_fs'] = fs_r2[roi_mat==True]\n",
    "\n",
    "                # get time\n",
    "                df_roi['time_fs'] = [np.arange(1,fs_ts.shape[3]+1)*TR]*np.sum(roi_mat==True)\n",
    "                df_roi['time_gaze'] = [np.arange(1,gc_ab_ts.shape[3]+1)*TR]*np.sum(roi_mat==True)\n",
    "\n",
    "                # get data timeseries\n",
    "                for main_task in ['fs', 'gc', 'gl', 'gr']:\n",
    "                    if main_task == 'fs':\n",
    "                        attend_tasks = ['', '_ab', '_af']\n",
    "                    else:\n",
    "                        attend_tasks = ['_ab', '_af']\n",
    "\n",
    "                    for attend_task in attend_tasks:\n",
    "                        exec(\"df_roi['data_{}{}'] = ({}{}_ts[roi_mat==True,:]).tolist()\".format(main_task, attend_task, main_task, attend_task))\n",
    "\n",
    "                        if roi_num == 11:\n",
    "                            if verbose: print(\"create df['data_{}{}']\".format(main_task, attend_task))\n",
    "                            exec(\"del {}{}_ts\".format(main_task, attend_task))\n",
    "                            if verbose: print(\"delete {}{}_ts from working memory\".format(main_task, attend_task))\n",
    "\n",
    "                df_roi['rank_r2_fs'] = df_roi.groupby('roi')['r2_fs'].rank(method='max', ascending=False)\n",
    "\n",
    "                # keep best 250\n",
    "                df_roi = df_roi[(df_roi.rank_r2_fs<=best_voxels_num)]\n",
    "\n",
    "                # across roi\n",
    "                if roi_num > 0: df2 = pd.concat([df2,df_roi], ignore_index=True)\n",
    "                else: df2 = df_roi\n",
    "\n",
    "            # add to df\n",
    "            df2.drop(['subject', 'roi', 'r2_fs', 'rank_r2_fs'], axis=1, inplace=True)\n",
    "            df = pd.concat([df,df2], axis=1)\n",
    "            del df2\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Load predictions and r2\n",
    "        print('\\nLoad predictions and r2...')\n",
    "        for main_task, main_task_short in zip(['FullScreen', 'GazeCenter', 'GazeLeft', 'GazeRight'],  ['fs', 'gc', 'gl', 'gr']):\n",
    "            if main_task == 'FullScreen': \n",
    "                attend_tasks = ['','AttendFix','AttendBar']\n",
    "                attend_tasks_short = ['','_af','_ab']\n",
    "                pred_names = ['fit_predictions']\n",
    "                pred_names_short = ['_pred']\n",
    "            else:\n",
    "                attend_tasks = ['AttendFix','AttendBar']\n",
    "                attend_tasks_short = ['_af','_ab']\n",
    "                pred_names = ['retinotopic_FullScreen-predictions',\n",
    "                              'spatiotopic_FullScreen-predictions']\n",
    "                pred_names_short = ['_retino_pred','_spatio_pred']\n",
    "\n",
    "            for attend_task, attend_task_short in zip(attend_tasks, attend_tasks_short):\n",
    "\n",
    "                for pred_name, pred_name_short in zip(pred_names, pred_names_short):\n",
    "                    # Only for best 250 voxels\n",
    "                    if type_analysis == '_best{}'.format(best_voxels_num):\n",
    "                        exec(\"{}{}{}_ts = nb.load('{}/{}_task-{}{}_{}.nii.gz').get_fdata()\".format(\n",
    "                                main_task_short, attend_task_short, pred_name_short,\n",
    "                                pred_dir, subject, main_task, attend_task, pred_name))\n",
    "                        if verbose: print(\"load {}{}{}_ts\".format(main_task_short, attend_task_short, pred_name_short))\n",
    "\n",
    "                    if main_task != 'FullScreen': \n",
    "                        exec(\"{}{}{}_r2 = nb.load('{}/{}_task-{}{}_{}_r2.nii.gz').get_fdata()*th_mat\".format(\n",
    "                                main_task_short, attend_task_short, pred_name_short,\n",
    "                                pred_dir, subject, main_task, attend_task, pred_name))\n",
    "                        if verbose: print(\"load {}{}{}_r2\".format(main_task_short, attend_task_short, pred_name_short))\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Add predictions and r2 to dataframe\n",
    "        print('\\nAdd predictions and r2 to dataframe...')\n",
    "        fs_r2 = nb.load('{}/{}_task-FullScreen_par-r2.nii.gz'.format(fit_dir,subject)).get_fdata()*th_mat\n",
    "        for roi_num, roi in enumerate(rois):\n",
    "            # load roi\n",
    "            lh_mat = nb.load(\"{}/{}_{}_L.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            rh_mat = nb.load(\"{}/{}_{}_R.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            roi_mat = lh_mat + rh_mat\n",
    "            roi_mat[roi_mat==0] = np.nan\n",
    "\n",
    "            # create dataframe\n",
    "            df_roi = pd.DataFrame({'subject': [subject] * fs_r2[roi_mat==True].shape[0]})\n",
    "            df_roi['roi'] = [roi] * fs_r2[roi_mat==True].shape[0]\n",
    "\n",
    "            # fullscreen r2 parameter\n",
    "            df_roi['r2_fs'] = fs_r2[roi_mat==True]\n",
    "\n",
    "            # get data timeseries\n",
    "            for main_task in ['fs', 'gc', 'gl', 'gr']:\n",
    "                if main_task == 'fs':\n",
    "                    attend_tasks = ['', '_ab', '_af']\n",
    "                    pred_names_short = ['pred']\n",
    "                else:\n",
    "                    attend_tasks = ['_ab', '_af']\n",
    "                    pred_names_short = ['retino_pred','spatio_pred']\n",
    "\n",
    "                for attend_task in attend_tasks:\n",
    "\n",
    "                    for pred_name_short in pred_names_short:\n",
    "                        # Only for best 250 voxels\n",
    "                        if type_analysis == '_best{}'.format(best_voxels_num):\n",
    "                            exec(\"df_roi['{}_{}{}'] = ({}{}_{}_ts[roi_mat==True,:]).tolist()\".format(pred_name_short, main_task, attend_task, \n",
    "                                                                                                  main_task, attend_task, pred_name_short))\n",
    "                            if roi_num == 11:\n",
    "                                if verbose: print(\"create df['{}_{}{}']\".format(pred_name_short, main_task, attend_task))\n",
    "                                exec(\"del {}{}_{}_ts\".format(main_task, attend_task, pred_name_short))\n",
    "                                if verbose: print(\"delete {}{}_{}_ts from working memory\".format(main_task, attend_task, pred_name_short))\n",
    "\n",
    "                        if main_task != 'fs': \n",
    "                            exec(\"df_roi['{}_{}{}_r2'] = ({}{}_{}_r2[roi_mat==True]).tolist()\".format(pred_name_short, main_task, attend_task, \n",
    "                                                                                                  main_task, attend_task, pred_name_short))\n",
    "                            if roi_num == 11:\n",
    "                                if verbose: print(\"create df['{}_{}{}_r2']\".format(pred_name_short, main_task, attend_task))\n",
    "                                exec(\"del {}{}_{}_r2\".format(main_task, attend_task, pred_name_short))\n",
    "                                if verbose: print(\"delete {}{}_{}_r2 from working memory\".format(main_task, attend_task, pred_name_short))\n",
    "\n",
    "\n",
    "            df_roi['rank_r2_fs'] = df_roi.groupby('roi')['r2_fs'].rank(method='max', ascending=False)\n",
    "\n",
    "            # keep best 250\n",
    "            if type_analysis == '_best{}'.format(best_voxels_num):\n",
    "                df_roi = df_roi[(df_roi.rank_r2_fs<=best_voxels_num)]\n",
    "\n",
    "            # across roi\n",
    "            if roi_num > 0: df2 = pd.concat([df2,df_roi], ignore_index=True)\n",
    "            else: df2 = df_roi\n",
    "\n",
    "        # add to df\n",
    "        df2.drop(['subject', 'roi', 'r2_fs', 'rank_r2_fs'], axis=1, inplace=True)\n",
    "        df = pd.concat([df,df2], axis=1)\n",
    "        del df2\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Save dataframe as tsv\n",
    "        df_fn = \"{}/{}_all_res{}.pkl\".format(tsv_dir,subject,type_analysis)\n",
    "        print('saving {}'.format(df_fn))\n",
    "        df.to_pickle(df_fn)\n",
    "        del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4465fa48-1032-47f8-8451-189db9137c09",
   "metadata": {},
   "source": [
    "#### Compute refit x parameter effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22f765-7cc3-4825-b100-8e6e0d818d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_analysis in type_analyses:\n",
    "    for subject in subjects:\n",
    "\n",
    "        print('\\n{}...'.format(subject))\n",
    "\n",
    "        # define folders\n",
    "        fit_dir = '{}/{}/prf/fit'.format(pp_dir, subject)\n",
    "        ref_index_dir = '{}/{}/prf/ref_index'.format(pp_dir, subject)\n",
    "        func_avg_dir = '{}/{}/func_avg'.format(pp_dir, subject)\n",
    "        pred_dir = '{}/{}/prf/predictions'.format(pp_dir, subject)\n",
    "        mask_dir = '{}/{}/masks'.format(pp_dir, subject)\n",
    "        tsv_dir = '{}/{}/prf/tsv'.format(pp_dir, subject)\n",
    "\n",
    "        try: os.makedirs(tsv_dir)\n",
    "        except: pass\n",
    "\n",
    "        # load pRF threshold masks\n",
    "        th_mat = nb.load('{}/{}_task-FullScreen_prf_threshold.nii.gz'.format(mask_dir,subject)).get_fdata()\n",
    "\n",
    "        # define empty coordinates index\n",
    "        x_idx, y_idx, z_idx = np.zeros_like(th_mat), np.zeros_like(th_mat), np.zeros_like(th_mat)\n",
    "        for x in np.arange(th_mat.shape[0]):\n",
    "            for y in np.arange(th_mat.shape[1]):\n",
    "                for z in np.arange(th_mat.shape[2]):\n",
    "                    x_idx[x,y,z], y_idx[x,y,z], z_idx[x,y,z] = x, y, z\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Load fit parameters\n",
    "        print('\\nLoad fit parameters...')\n",
    "        for attend_task, attend_task_short in zip(['','AttendFix','AttendBar'], ['', '_af', '_ab']):\n",
    "            for fit_param in ['amplitude','baseline','ecc','r2','sd','x','y','theta']:\n",
    "                exec(\"fs{}_{} = nb.load('{}/{}_task-FullScreen{}_par-{}.nii.gz').get_fdata()*th_mat\".format(\n",
    "                    attend_task_short,fit_param,fit_dir,subject,attend_task,fit_param))\n",
    "                if verbose: print(\"load fs{}_{}\".format(attend_task_short,fit_param))\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Create dataframe with fit parameters\n",
    "        print('\\nCreate dataframe with fit parameters...')\n",
    "        for roi_num, roi in enumerate(rois):\n",
    "            # load roi\n",
    "            lh_mat = nb.load(\"{}/{}_{}_L.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            rh_mat = nb.load(\"{}/{}_{}_R.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            roi_mat = lh_mat + rh_mat\n",
    "            roi_mat[roi_mat==0] = np.nan\n",
    "\n",
    "            # create dataframe\n",
    "            df_roi = pd.DataFrame({'subject': [subject] * fs_r2[roi_mat==True].shape[0]})\n",
    "            df_roi['roi'] = [roi] * fs_r2[roi_mat==True].shape[0]\n",
    "            df_roi['vox_coord'] = np.array([x_idx[roi_mat==True],y_idx[roi_mat==True],z_idx[roi_mat==True]]).T.tolist()        \n",
    "\n",
    "            # fullscreen parameters\n",
    "            for attend_task in ['', '_ab', '_af']:\n",
    "                for fit_param in ['amplitude','baseline','ecc','r2','sd','x','y','theta']:\n",
    "                    exec(\"df_roi['{}_fs{}'] = fs{}_{}[roi_mat==True]\".format(fit_param, attend_task, attend_task, fit_param))\n",
    "                    if roi_num == 11:\n",
    "                        if verbose: print(\"create df['{}_fs{}']\".format(fit_param, attend_task))\n",
    "                        exec(\"del fs{}_{}\".format(attend_task, fit_param))\n",
    "                        if verbose: print(\"delete fs{}_{} from working memory\".format(attend_task, fit_param))\n",
    "\n",
    "            # get rank with fs\n",
    "            df_roi['rank_r2_fs'] = df_roi.groupby('roi')['r2_fs'].rank(method='max', ascending=False)\n",
    "\n",
    "            # keep best 250\n",
    "            if type_analysis == '_best{}'.format(best_voxels_num):\n",
    "                df_roi = df_roi[(df_roi.rank_r2_fs<=best_voxels_num)]\n",
    "\n",
    "            # across roi\n",
    "            if roi_num > 0: df = pd.concat([df,df_roi], ignore_index=True)\n",
    "            else: df = df_roi\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Load refit parameters\n",
    "        print('\\nLoad refit parameters...')\n",
    "        for attend_task, attend_task_short in zip(['AttendFix','AttendBar'],['af','ab']):\n",
    "            for gaze_task, gaze_task_short in zip(['GazeCenter','GazeLeft','GazeRight'],['gc','gl','gr']):\n",
    "                for fit_type, fit_type_short in zip(['optim','startwith-retinotopic','startwith-spatiotopic'],['optim','start_retino','start_spatio']):\n",
    "                    for fit_param in ['amplitude','baseline','ecc','r2','sd','x','y','theta']:\n",
    "                        exec(\"{}_{}_{}_{} = nb.load('{}/{}_task-{}{}_{}_par-{}.nii.gz').get_fdata()*th_mat\".format(\n",
    "                                gaze_task_short, attend_task_short, fit_type_short,fit_param, \n",
    "                                fit_dir, subject, gaze_task, attend_task, fit_type, fit_param))\n",
    "                        if verbose: print(\"load {}_{}_{}_{}\".format(gaze_task_short, attend_task_short, fit_type_short,fit_param))\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Add refit parameters to dataframe\n",
    "        print('\\nAdd refit parameters to dataframe...')\n",
    "        fs_r2 = nb.load('{}/{}_task-FullScreen_par-r2.nii.gz'.format(fit_dir,subject)).get_fdata()*th_mat\n",
    "\n",
    "        for roi_num, roi in enumerate(rois):\n",
    "            # load roi\n",
    "            lh_mat = nb.load(\"{}/{}_{}_L.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            rh_mat = nb.load(\"{}/{}_{}_R.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            roi_mat = lh_mat + rh_mat\n",
    "            roi_mat[roi_mat==0] = np.nan\n",
    "\n",
    "            # create dataframe\n",
    "            df_roi = pd.DataFrame({'subject': [subject] * fs_r2[roi_mat==True].shape[0]})\n",
    "            df_roi['roi'] = [roi] * fs_r2[roi_mat==True].shape[0]\n",
    "\n",
    "            # fullscreen r2 parameter\n",
    "            df_roi['r2_fs'] = fs_r2[roi_mat==True]\n",
    "\n",
    "            # get data timeseries\n",
    "            for gaze_task in ['gc', 'gl', 'gr']:\n",
    "                for attend_task in ['af', 'ab']:\n",
    "                    for fit_type in ['optim', 'start_retino', 'start_spatio']:\n",
    "                        for fit_param in ['amplitude', 'baseline', 'ecc', 'r2', 'sd', 'x', 'y','theta']:\n",
    "                            exec(\"df_roi['{}_{}_{}_{}'] = {}_{}_{}_{}[roi_mat==True]\".format(gaze_task, attend_task, fit_type, fit_param,\n",
    "                                                                                             gaze_task, attend_task, fit_type, fit_param))\n",
    "\n",
    "                            if roi_num == 11:\n",
    "                                if verbose: print(\"create df['{}_{}_{}_{}']\".format(gaze_task, attend_task, fit_type, fit_param))\n",
    "                                exec(\"del {}_{}_{}_{}\".format(gaze_task, attend_task, fit_type, fit_param))\n",
    "                                if verbose: print(\"delete {}_{}_{}_{} from working memory\".format(gaze_task, attend_task, fit_type, fit_param))\n",
    "\n",
    "            df_roi['rank_r2_fs'] = df_roi.groupby('roi')['r2_fs'].rank(method='max', ascending=False)\n",
    "\n",
    "            # keep best 250\n",
    "            if type_analysis == '_best{}'.format(best_voxels_num):\n",
    "                df_roi = df_roi[(df_roi.rank_r2_fs<=best_voxels_num)]\n",
    "\n",
    "            # across roi\n",
    "            if roi_num > 0: df2 = pd.concat([df2,df_roi], ignore_index=True)\n",
    "            else: df2 = df_roi\n",
    "\n",
    "        # add to df\n",
    "        df2.drop(['subject', 'roi', 'r2_fs', 'rank_r2_fs'], axis=1, inplace=True)\n",
    "        df = pd.concat([df,df2], axis=1)\n",
    "        del df2\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Load reference frame index\n",
    "        print('\\nLoad reference frame index...')\n",
    "        for attend_task, attend_task_short in zip(['AttendFix','AttendBar'],['af','ab']):\n",
    "\n",
    "            exec(\"{}_ref_index_nb = nb.load('{}/{}_task-{}_refit_ref_index.nii.gz')\".format(attend_task_short, ref_index_dir, subject, attend_task))\n",
    "            exec(\"{}_ref_index = {}_ref_index_nb.get_fdata().reshape({}_ref_index_nb.shape[:-1])*th_mat\".format(attend_task_short,attend_task_short,attend_task_short))\n",
    "            if verbose: print(\"load {}_ref_index\".format(attend_task_short))\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Add reference frame index to dataframe\n",
    "        print('\\nAdd reference frame index to dataframe...')\n",
    "        fs_r2 = nb.load('{}/{}_task-FullScreen_par-r2.nii.gz'.format(fit_dir,subject)).get_fdata()*th_mat\n",
    "\n",
    "        for roi_num, roi in enumerate(rois):\n",
    "            # load roi\n",
    "            lh_mat = nb.load(\"{}/{}_{}_L.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            rh_mat = nb.load(\"{}/{}_{}_R.nii.gz\".format(mask_dir, roi, cortical_mask)).get_fdata()\n",
    "            roi_mat = lh_mat + rh_mat\n",
    "            roi_mat[roi_mat==0] = np.nan\n",
    "\n",
    "            # create dataframe\n",
    "            df_roi = pd.DataFrame({'subject': [subject] * fs_r2[roi_mat==True].shape[0]})\n",
    "            df_roi['roi'] = [roi] * fs_r2[roi_mat==True].shape[0]\n",
    "\n",
    "            # fullscreen r2 parameter\n",
    "            df_roi['r2_fs'] = fs_r2[roi_mat==True]\n",
    "\n",
    "            # get ref index\n",
    "            for attend_task in ['af', 'ab']:\n",
    "                exec(\"df_roi['{}_ref_index'] = {}_ref_index[roi_mat==True]\".format(attend_task, attend_task))\n",
    "\n",
    "                if roi_num == 11:\n",
    "                    if verbose: print(\"create df['{}_ref_index']\".format(attend_task))\n",
    "                    exec(\"del {}_ref_index\".format(attend_task))\n",
    "                    if verbose: print(\"delete {}_ref_index from working memory\".format(attend_task))\n",
    "\n",
    "            df_roi['rank_r2_fs'] = df_roi.groupby('roi')['r2_fs'].rank(method='max', ascending=False)\n",
    "\n",
    "            # keep best 250\n",
    "            if type_analysis == '_best{}'.format(best_voxels_num):\n",
    "                df_roi = df_roi[(df_roi.rank_r2_fs<=best_voxels_num)]\n",
    "            \n",
    "            # across roi\n",
    "            if roi_num > 0: df2 = pd.concat([df2,df_roi], ignore_index=True)\n",
    "            else: df2 = df_roi\n",
    "\n",
    "        # add to df\n",
    "        df2.drop(['subject', 'roi', 'r2_fs', 'rank_r2_fs'], axis=1, inplace=True)\n",
    "        df = pd.concat([df,df2], axis=1)\n",
    "        del df2\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------\n",
    "        # Save dataframe as tsv\n",
    "        df_fn = \"{}/{}_refit_res{}.pkl\".format(tsv_dir,subject,type_analysis)\n",
    "        print('saving {}'.format(df_fn))\n",
    "        df.to_pickle(df_fn)\n",
    "        del df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530429a-85ac-4f63-ba43-0de22807d456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mszinte",
   "language": "python",
   "name": "mszinte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
